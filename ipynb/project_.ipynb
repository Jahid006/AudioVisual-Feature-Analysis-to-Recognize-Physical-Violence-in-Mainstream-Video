{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f064f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, time, shutil, os, joblib, tqdm, pickle, json, pprint\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd1ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input, layers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cc7e89a",
   "metadata": {},
   "source": [
    "import cv2, pims\n",
    "import glob, decord\n",
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "decord.bridge.set_bridge('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4a7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BACKBONE, USE_MY_DATASET, USE_RLVS_DATASET, INPUT_DIM, IF_MXNET_MODEL,\\\n",
    "    PATH, HISTORY_PATH, LOG_PATH, MODEL_PATH, RESULT_PATH, DEBUG, CROSS_DATASET, PARTITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3fa79c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Backbone': 'P3D',\n",
      " 'Cross_Dataset': '',\n",
      " 'Debug': True,\n",
      " 'History_Path': './models_history/P3D_My_Dataset_Rlvs_Dataset',\n",
      " 'If_Mxnet_Model': True,\n",
      " 'Input_Dim': (2, 2048),\n",
      " 'Log_Path': './tensorboard_log/P3D_My_Dataset_Rlvs_Dataset',\n",
      " 'Model_Path': './saved_models/P3D_My_Dataset_Rlvs_Dataset',\n",
      " 'Partition': 0.9,\n",
      " 'Path': 'P3D_My_Dataset_Rlvs_Dataset',\n",
      " 'Result_Path': './generated_result/P3D_My_Dataset_Rlvs_Dataset',\n",
      " 'Use_My_Dataset': True,\n",
      " 'Use_Rlvs_Dataset': True}\n"
     ]
    }
   ],
   "source": [
    "model_configuration ={'Backbone':BACKBONE,\n",
    "                      'Use_My_Dataset':USE_MY_DATASET,\n",
    "                      'Use_Rlvs_Dataset':USE_RLVS_DATASET,\n",
    "                      'Input_Dim':INPUT_DIM,\n",
    "                      'If_Mxnet_Model':IF_MXNET_MODEL,\n",
    "                      'Path':PATH,\n",
    "                      'History_Path':HISTORY_PATH,\n",
    "                      'Log_Path':LOG_PATH,\n",
    "                      'Model_Path':MODEL_PATH,\n",
    "                      'Result_Path':RESULT_PATH,\n",
    "                      'Debug':DEBUG,\n",
    "                      'Cross_Dataset':CROSS_DATASET,\n",
    "                      'Partition':PARTITION}\n",
    "\n",
    "pprint.pprint(model_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6d6dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "[make_dir(i) for i in [HISTORY_PATH, LOG_PATH, MODEL_PATH, RESULT_PATH]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da87bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKBONE = \"denseNet201\"\n",
    "#from tensorflow.keras.applications.densenet import preprocess_input\n",
    "#backbone = tf.keras.applications.DenseNet201(include_top=False,weights=\"imagenet\",pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f219da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def times():\n",
    "    now = datetime.now()\n",
    "    return str(now.strftime(\"%d-%m-%Y..%H.%M.%S\"))\n",
    "\n",
    "def save(name,data,about=\"Undocumented\"):\n",
    "    \n",
    "    '''This function saves file as sav with Time extension'''\n",
    "    about += \" at \"+times()\n",
    "    filename = name +\"_\"+ times()+'.sav' \n",
    "    joblib.dump([about,data], filename)\n",
    "    print('Successfully Pickled->',name)\n",
    "    \n",
    "def Load(name):\n",
    "    about,data = joblib.load(name)\n",
    "    print(\"About \"+name+\": \\n\"+about)\n",
    "    return data\n",
    "\n",
    "def ShuffleIndex(l,seed=42):\n",
    "    permutation  = np.random.RandomState(seed=seed).permutation((l))\n",
    "    inversePermutation = np.argsort(permutation)\n",
    "    return permutation, inversePermutation\n",
    "\n",
    "def dict_as_json(data, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "        \n",
    "def json_to_dict(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "48c15a57",
   "metadata": {},
   "source": [
    "def ExtractFeature(FileName,frames = 16, width=224, height=224):\n",
    "    \n",
    "    V = pims.Video(FileName) \n",
    "    duration = len(V) \n",
    "      \n",
    "    try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "    except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "    \n",
    "    Frames = np.array(V[frame_id_list])\n",
    "    Frames = np.array([cv2.resize(frame,(width,height)) for frame in Frames])\n",
    "    features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    return features\n",
    "\n",
    "\n",
    "def ExtractFeatureDecord(FileName,frames = 16, width=224, height=224):\n",
    "    \n",
    "    try:\n",
    "        V = VideoReader(FileName, width, height)\n",
    "        duration = len(V)\n",
    "        try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "        except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "        \n",
    "        Frames = V.get_batch(frame_id_list).asnumpy()\n",
    "        features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    \n",
    "    except:return ExtractFeature(FileName,frames,width,height)\n",
    "    return features\n",
    "\n",
    "def ExtractFeatureCV2(FileName,frames = 16, width=224, height=224):\n",
    "    \"\"\"get frames from video using cv2\"\"\"\n",
    "    V = cv2.VideoCapture(FileName)\n",
    "    duration = int(V.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "    except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "    \n",
    "    Frames = np.array([V.read()[1] for i in frame_id_list])\n",
    "    Frames = np.array([cv2.resize(frame,(width,height)) for frame in Frames])\n",
    "    features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f14ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dimension = 512,summary = False,input_shape = INPUT_DIM):\n",
    "    \n",
    "    FeatureInput = Input(shape=input_shape)\n",
    "    Average_feature = layers.Flatten()(FeatureInput) if  IF_MXNET_MODEL else tf.reduce_max(FeatureInput,-2)*.25 + tf.reduce_mean(FeatureInput,-2)*.75\n",
    "    \n",
    "    AudioInput =   Input(shape=(1024))\n",
    "    audio_ = layers.Dense(dimension//4,kernel_initializer='normal', activation='linear')(AudioInput)\n",
    "    audio_ = layers.BatchNormalization()(audio_)\n",
    "    audio_ = layers.Activation(tf.nn.relu)(audio_)\n",
    "    audio_ = layers.Dropout(.5)(audio_)\n",
    "    \n",
    "    video_ = layers.Flatten()(Average_feature)\n",
    "    video_ = layers.Dense(dimension//2,kernel_initializer='normal', activation='linear')(video_)\n",
    "    video_ = layers.BatchNormalization()(video_)\n",
    "    video_ = layers.Activation(tf.nn.relu)(video_)\n",
    "    video_ = layers.Dropout(.5)(video_)\n",
    "    \n",
    "    combined = layers.concatenate([video_,audio_],axis=1)\n",
    "    \n",
    "    output = layers.Dense(1,kernel_initializer='normal', activation='sigmoid',name = 'classifier')(combined)\n",
    "    \n",
    "    model = Model(inputs= [FeatureInput,AudioInput], outputs = output)\n",
    "    model.compile(optimizer=tf.optimizers.Nadam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    if summary:print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973c6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_callbacks():\n",
    "    \"\"\"define models callbacks\"\"\"#checkpoint = tf.keras.callbacks.ModelCheckpoint('violenceNet.h5',save_best_only=True)\n",
    "    my_callbacks = [#tf.keras.callbacks.EarlyStopping(patience=10,min_delta= .005,mode='auto',monitor=\"val_accuracy\"),\n",
    "                    tf.keras.callbacks.ModelCheckpoint(filepath = MODEL_PATH+'\\model.{epoch:02d}-{val_loss:.2f}-{val_accuracy:.3f}.h5'),\n",
    "                    tf.keras.callbacks.TensorBoard(log_dir=LOG_PATH),]\n",
    "    \n",
    "    return my_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee421aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_data(DEBUG=False):\n",
    "    positive_video = glob.glob(f'video_features\\my_dataset\\{BACKBONE}\\\\notPhysicalViolence\\*')\n",
    "    negative_video = glob.glob(f'video_features\\my_dataset\\{BACKBONE}\\PhysicalViolence\\*')\n",
    "    \n",
    "    positive_audio_embedding = glob.glob(r'audio_features\\my_dataset\\notPhysicalViolence\\*')\n",
    "    negative_audio_embedding = glob.glob(f'audio_features\\my_dataset\\PhysicalViolence\\*')\n",
    "    \n",
    "    video_files = positive_video + negative_video\n",
    "    audio_files = positive_audio_embedding + negative_audio_embedding\n",
    "    \n",
    "    print(f'{len(video_files)} videos and {len(audio_files)} audio files found in my dataset')\n",
    "    \n",
    "    videos = [np.load(video_files[k],allow_pickle=True) for k in range(len(video_files))]\n",
    "    audios = [np.load(audio_files[k],allow_pickle=True).flatten() for k in range(len(audio_files))]\n",
    "    labels = [0]*len(positive_video) + [1]*len(negative_video)\n",
    "    \n",
    "    videos = np.array(videos,dtype=np.float32)\n",
    "    audios = np.array(audios,dtype=np.float32)\n",
    "    labels = np.array(labels,dtype=np.int32)\n",
    "    \n",
    "    if DEBUG:\n",
    "        idx = np.random.choice(range(len(videos)),size=10,replace=False)\n",
    "        print('\\n',list(zip(np.array(video_files)[idx],np.array(audio_files)[idx],labels[idx])))\n",
    "\n",
    "    print('my data shape: ',videos.shape,audios.shape,labels.shape)\n",
    "    \n",
    "    return videos, audios, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlvs_audios_embedding_not_found = []\n",
    "\n",
    "def get_audio_embedding(audio_file):\n",
    "    if os.path.exists(audio_file):\n",
    "        return np.load(audio_file,allow_pickle=True).flatten()\n",
    "    \n",
    "    rlvs_audios_embedding_not_found.append(audio_file)\n",
    "    return np.zeros(1024).flatten()\n",
    "\n",
    "def naming(video_file):\n",
    "    name  = video_file.split('\\\\')[-1][:-4]\n",
    "    if name.split('.')[-1] in ['i3d10s','p3d5s','r21d']:\n",
    "        name = name.replace('.'+name.split('.')[-1],'')\n",
    "    return f'audio_features\\\\rlvs\\{name}.npy'\n",
    "\n",
    "def get_rlvs_data(DEBUG=False): \n",
    "    video_files = glob.glob(f'video_features\\\\rlvs\\{BACKBONE}\\*')\n",
    "    \n",
    "    print(f'{len(video_files)} videos found in rlvs dataset')\n",
    "\n",
    "    videos = [np.load(video_files[k],allow_pickle=True) for k in range(len(video_files))]\n",
    "    audios = [get_audio_embedding(naming(k)) for k in video_files]\n",
    "    \n",
    "    class_map = {'NV':0,'V':1}\n",
    "    labels = [class_map[i.split('\\\\')[-1].split('_')[0]] for i in video_files]\n",
    "    \n",
    "    videos = np.array(videos,dtype=np.float32)\n",
    "    audios = np.array(audios,dtype=np.float32)\n",
    "    labels = np.array(labels,dtype=np.int32)\n",
    "    \n",
    "    if DEBUG:\n",
    "        idx = np.random.choice(range(len(videos)),size=10,replace=False)\n",
    "        print('\\n',list(zip(np.array(video_files)[idx],\n",
    "                       [(naming(k)) for k in np.array(video_files)[idx]],\n",
    "                       labels[idx])))\n",
    "    \n",
    "    print(\"rlvs data shape: \",videos.shape,audios.shape,labels.shape)\n",
    "    print(f'{len(rlvs_audios_embedding_not_found)} audio files not found')\n",
    "    \n",
    "    return videos, audios, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0efd1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(my_data = False, rlvs = False,DEBUG=False):\n",
    "    videos, audios, labels = None, None, None\n",
    "    \n",
    "    if my_data:\n",
    "        my_videos, my_audios, my_labels = get_my_data(DEBUG)\n",
    "        videos = np.concatenate((videos,my_videos), axis = 0) if videos is not None else my_videos\n",
    "        audios = np.concatenate((audios,my_audios), axis = 0) if audios is not None else my_audios\n",
    "        labels = np.concatenate((labels,my_labels), axis = 0) if labels is not None else my_labels\n",
    "\n",
    "    if rlvs:\n",
    "        rlvs_videos, rlvs_audios, rlvs_labels = get_rlvs_data(DEBUG)\n",
    "        videos = np.concatenate((videos,rlvs_videos), axis = 0) if videos is not None else rlvs_videos\n",
    "        audios = np.concatenate((audios,rlvs_audios), axis = 0) if audios is not None else rlvs_audios\n",
    "        labels = np.concatenate((labels,rlvs_labels), axis = 0) if labels is not None else rlvs_labels\n",
    "     \n",
    "    return videos, audios, labels\n",
    "\n",
    "def get_shuffled_data(videos, audios, labels,from_storage= None):\n",
    "    \n",
    "    if from_storage: \n",
    "        permutation, inversePermutation = np.load('history\\permutation_index.npy',allow_pickle=True)\n",
    "    else:  permutation, inversePermutation = ShuffleIndex(len(videos))\n",
    "    \n",
    "    videos = videos[permutation]\n",
    "    audios = audios[permutation]\n",
    "    labels = labels[permutation]\n",
    "    \n",
    "    #np.save('config\\permutation_index.npy',[permutation, inversePermutation],allow_pickle=True)\n",
    "    return videos, audios, labels, permutation, inversePermutation   \n",
    "\n",
    "def split_train_test_data(videos, audios, labels,partition = PARTITION):\n",
    "    \"\"\"split data into train, test, validation\"\"\"\n",
    "    \n",
    "    if partition<=1:  partition = int(len(videos)*partition)\n",
    "    \n",
    "    train_videos = videos[:partition]\n",
    "    train_audios = audios[:partition]\n",
    "    train_labels = labels[:partition]\n",
    "    \n",
    "    test_videos = videos[partition:]\n",
    "    test_audios = audios[partition:]\n",
    "    test_labels = labels[partition:]\n",
    "\n",
    "    \n",
    "    \n",
    "    return train_videos, train_audios, train_labels, test_videos, test_audios, test_labels\n",
    "    \n",
    "def get_data_generator(videos, audios, labels, batch_size):\n",
    "    while True:\n",
    "        permutation, inversePermutation = ShuffleIndex(len(videos))\n",
    "        videos = videos[permutation]\n",
    "        audios = audios[permutation]\n",
    "        labels = labels[permutation]\n",
    "        \n",
    "        for i in range(0,len(videos),batch_size):\n",
    "            yield videos[i:i+batch_size], audios[i:i+batch_size], labels[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac7ba300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 2048)]    0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4096)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          524416      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           65600       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64)          256         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64)           0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            193         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 590,977\n",
      "Trainable params: 590,593\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(dimension = 256, summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f56bc527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216 videos and 1216 audio files found in my dataset\n",
      "\n",
      " [('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\1667.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\1667.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\1465.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\1465.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\PhysicalViolence\\\\3139.Violence.p3d5s.npy', 'audio_features\\\\my_dataset\\\\PhysicalViolence\\\\3139.Violence.npy', 1), ('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\1633.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\1633.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\3205.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\3205.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\1681.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\1681.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\PhysicalViolence\\\\3050.Violence.p3d5s.npy', 'audio_features\\\\my_dataset\\\\PhysicalViolence\\\\3050.Violence.npy', 1), ('video_features\\\\my_dataset\\\\P3D\\\\notPhysicalViolence\\\\1971.Vanilla.p3d5s.npy', 'audio_features\\\\my_dataset\\\\notPhysicalViolence\\\\1971.Vanilla.npy', 0), ('video_features\\\\my_dataset\\\\P3D\\\\PhysicalViolence\\\\3348.p3d5s.npy', 'audio_features\\\\my_dataset\\\\PhysicalViolence\\\\3348.npy', 1), ('video_features\\\\my_dataset\\\\P3D\\\\PhysicalViolence\\\\2958.p3d5s.npy', 'audio_features\\\\my_dataset\\\\PhysicalViolence\\\\2958.npy', 1)]\n",
      "my data shape:  (1216, 2, 2048) (1216, 1024) (1216,)\n",
      "2000 videos found in rlvs dataset\n",
      "\n",
      " [('video_features\\\\rlvs\\\\P3D\\\\V_751.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_751.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\V_166.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_166.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\NV_662.p3d5s.npy', 'audio_features\\\\rlvs\\\\NV_662.npy', 0), ('video_features\\\\rlvs\\\\P3D\\\\V_223.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_223.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\V_750.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_750.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\V_859.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_859.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\NV_643.p3d5s.npy', 'audio_features\\\\rlvs\\\\NV_643.npy', 0), ('video_features\\\\rlvs\\\\P3D\\\\V_654.p3d5s.npy', 'audio_features\\\\rlvs\\\\V_654.npy', 1), ('video_features\\\\rlvs\\\\P3D\\\\NV_190.p3d5s.npy', 'audio_features\\\\rlvs\\\\NV_190.npy', 0), ('video_features\\\\rlvs\\\\P3D\\\\NV_160.p3d5s.npy', 'audio_features\\\\rlvs\\\\NV_160.npy', 0)]\n",
      "rlvs data shape:  (2000, 2, 2048) (2000, 1024) (2000,)\n",
      "1062 audio files not found\n"
     ]
    }
   ],
   "source": [
    "videos, audios, labels = get_all_data(my_data = USE_MY_DATASET, rlvs = USE_RLVS_DATASET, DEBUG=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c84f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos, audios, labels, perm, Iperm = get_shuffled_data(videos, audios, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63190e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2894 train videos, 322 test videos\n"
     ]
    }
   ],
   "source": [
    "train_videos, train_audios, train_labels, test_videos, test_audios, test_labels = split_train_test_data(videos, audios, labels)\n",
    "if len(CROSS_DATASET):\n",
    "    print('\\n','Cross dataset evaluation: ',CROSS_DATASET)\n",
    "    test_videos, test_audios, test_labels = get_rlvs_data() if CROSS_DATASET =='rlvs' else get_my_data()\n",
    "    \n",
    "print(f'\\n\\n{len(train_videos)} train videos, {len(test_videos)} test videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a55228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 3s 36ms/step - loss: 0.3632 - accuracy: 0.8437 - val_loss: 0.4281 - val_accuracy: 0.9034\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.2106 - accuracy: 0.9313 - val_loss: 0.3337 - val_accuracy: 0.9172\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 0.1464 - accuracy: 0.9558 - val_loss: 0.2561 - val_accuracy: 0.9448\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1208 - accuracy: 0.9658 - val_loss: 0.2391 - val_accuracy: 0.9000\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.2449 - val_accuracy: 0.8862\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 0.1554 - val_accuracy: 0.9448\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0666 - accuracy: 0.9854 - val_loss: 0.1413 - val_accuracy: 0.9655\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0542 - accuracy: 0.9881 - val_loss: 0.1881 - val_accuracy: 0.9276\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0495 - accuracy: 0.9881 - val_loss: 0.3209 - val_accuracy: 0.8655\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0432 - accuracy: 0.9912 - val_loss: 0.1266 - val_accuracy: 0.9414\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0309 - accuracy: 0.9946 - val_loss: 0.1222 - val_accuracy: 0.9483\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.1500 - val_accuracy: 0.9448\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0379 - accuracy: 0.9916 - val_loss: 0.1133 - val_accuracy: 0.9552\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0326 - accuracy: 0.9916 - val_loss: 0.1919 - val_accuracy: 0.9172\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0283 - accuracy: 0.9954 - val_loss: 0.1428 - val_accuracy: 0.9483\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.1336 - val_accuracy: 0.9345\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0205 - accuracy: 0.9958 - val_loss: 0.1357 - val_accuracy: 0.9379\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0229 - accuracy: 0.9965 - val_loss: 0.1648 - val_accuracy: 0.9379\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0167 - accuracy: 0.9981 - val_loss: 0.1482 - val_accuracy: 0.9448\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.2174 - val_accuracy: 0.9276\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.1542 - val_accuracy: 0.9379\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1674 - val_accuracy: 0.9345\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.1689 - val_accuracy: 0.9448\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 0.3554 - val_accuracy: 0.8828\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0158 - accuracy: 0.9973 - val_loss: 0.6479 - val_accuracy: 0.8138\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.1703 - val_accuracy: 0.9414\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.1615 - val_accuracy: 0.9448\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9379\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0119 - accuracy: 0.9981 - val_loss: 0.1921 - val_accuracy: 0.9379\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0111 - accuracy: 0.9981 - val_loss: 0.1661 - val_accuracy: 0.9379\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.1618 - val_accuracy: 0.9241\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.1991 - val_accuracy: 0.9310\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.1313 - val_accuracy: 0.9379\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.2426 - val_accuracy: 0.9276\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.2164 - val_accuracy: 0.9241\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.1538 - val_accuracy: 0.9379\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.8984 - val_accuracy: 0.7690\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0137 - accuracy: 0.9969 - val_loss: 0.3161 - val_accuracy: 0.9034\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.1376 - val_accuracy: 0.9483\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.1639 - val_accuracy: 0.9414\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1481 - val_accuracy: 0.9379\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.3054 - val_accuracy: 0.8931\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1501 - val_accuracy: 0.9483\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.2794 - val_accuracy: 0.8966\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1266 - val_accuracy: 0.9448\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.1505 - val_accuracy: 0.9379\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.1592 - val_accuracy: 0.9379\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1555 - val_accuracy: 0.9483\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.2067 - val_accuracy: 0.9345\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.1733 - val_accuracy: 0.9448\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_videos,train_audios],train_labels, epochs=50,\n",
    "                    verbose=1,steps_per_epoch=32,validation_split=.1,shuffle = True,\n",
    "                    callbacks = get_callbacks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c9860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{HISTORY_PATH}\\history.npy',history.history)\n",
    "dict_as_json(history.history,HISTORY_PATH+'\\history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141ee65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('model\\\\violence_my_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34ce38e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76e66662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(history):\n",
    "    \"\"\"get the best model from history\"\"\"\n",
    "    best_epoch = np.argmin(history['val_loss'])\n",
    "    return history['model'][best_epoch]\n",
    "def get_best_model_from_storage(path = MODEL_PATH):\n",
    "    models_ = glob.glob(path+'\\*.h5')\n",
    "    best_model = np.argmax([int(i.split('\\\\')[-1].split('.')[-2]) for i in models_])\n",
    "    print(f'best model is {models_[best_model]}')\n",
    "    return models_[best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37ba8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is ./saved_models/P3D_My_Dataset_Rlvs_Dataset\\model.07-0.14-0.966.h5\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(get_best_model_from_storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9afc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([test_videos,test_audios],verbose=1,steps=len(test_videos)//64)\n",
    "prediction = np.round(prediction,2)\n",
    "classification = np.rint(prediction).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3102d738",
   "metadata": {},
   "source": [
    "f\"Accuracy: {np.sum(classification==test_labels)/len(test_labels)}, {np.sum(classification==test_labels)} out of {len(test_labels)} datapoint were correctly classified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "878627d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(a,b,v=0): #actual,predicted\n",
    "    a = np.array(a).astype(int)\n",
    "    b = np.array(b).astype(int)\n",
    "    if v: \n",
    "        a = 1-a\n",
    "        b = 1-b\n",
    "\n",
    "    tp = sum((a==0) & (b==0))\n",
    "    tn = sum((a==1) & (b==1))\n",
    "    fn = sum((a==0) & (b==1))\n",
    "    fp = sum((a==1) & (b==0))\n",
    "    #print(\"TP: \",tp,\" TN: \",tn,' FN: ',fn,' FP: ',fp)\n",
    "    \n",
    "    confusion_matrix = {'TP': int(tp), 'TN': int(tn), 'FN': int(fn), 'FP': int(fp)}\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn) \n",
    "    f1_score = (2*precision*recall)/ (precision+recall)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    support = sum(a==v)\n",
    "    accuracy ,precision,recall,f1_score,support = np.round([accuracy ,precision,recall,f1_score,support],3)\n",
    "    \n",
    "    report = {'class':v,\n",
    "              'No of test samples':len(a),\n",
    "              'support': int(support),\n",
    "              'confusion_matrix':confusion_matrix,\n",
    "              'accuracy':accuracy,\n",
    "              'precision':precision,\n",
    "              'recall':recall,\n",
    "              'f1_score':f1_score\n",
    "              }\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed16248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf0cad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is ./saved_models/P3D_My_Dataset_Rlvs_Dataset\\model.07-0.14-0.966.h5\n",
      "{'BACKBONE': 'P3D',\n",
      " 'Best model': './saved_models/P3D_My_Dataset_Rlvs_Dataset\\\\model.07-0.14-0.966.h5',\n",
      " 'INPUT_DIM': (2, 2048),\n",
      " 'My dataset': True,\n",
      " 'No Physical Violence': {'No of test samples': 322,\n",
      "                          'accuracy': 0.938,\n",
      "                          'class': 0,\n",
      "                          'confusion_matrix': {'FN': 14,\n",
      "                                               'FP': 6,\n",
      "                                               'TN': 156,\n",
      "                                               'TP': 146},\n",
      "                          'f1_score': 0.936,\n",
      "                          'precision': 0.961,\n",
      "                          'recall': 0.912,\n",
      "                          'support': 160},\n",
      " 'Physical Violence': {'No of test samples': 322,\n",
      "                       'accuracy': 0.938,\n",
      "                       'class': 1,\n",
      "                       'confusion_matrix': {'FN': 6,\n",
      "                                            'FP': 14,\n",
      "                                            'TN': 146,\n",
      "                                            'TP': 156},\n",
      "                       'f1_score': 0.94,\n",
      "                       'precision': 0.918,\n",
      "                       'recall': 0.963,\n",
      "                       'support': 160},\n",
      " 'RLVS dataset': True,\n",
      " 'Time': '28-12-2021..23.55.39',\n",
      " 'model_name': 'P3D_My_Dataset_Rlvs_Dataset'}\n"
     ]
    }
   ],
   "source": [
    "result = {'Time':times(),\n",
    "          'model_name':PATH,\n",
    "          'My dataset':USE_MY_DATASET,\n",
    "          'RLVS dataset':USE_RLVS_DATASET,\n",
    "          'BACKBONE':BACKBONE,\n",
    "          'INPUT_DIM':INPUT_DIM,\n",
    "          'No Physical Violence':generate_report(test_labels,classification,0),\n",
    "          'Physical Violence':   generate_report(test_labels,classification,1),\n",
    "          'Best model':get_best_model_from_storage()\n",
    "          }\n",
    "\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4372056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_as_json(result,RESULT_PATH+'\\\\result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050c665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99d05196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0.698, 1396)\n",
    "#(0.8187633262260128, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ecac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c142bfec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8996446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 ^ 1,1^0,0^0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9e2387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0004,\n",
       " 0.0004,\n",
       " 0.0004,\n",
       " 0.0004,\n",
       " 0.0004,\n",
       " 0.000268,\n",
       " 0.000268,\n",
       " 0.000268,\n",
       " 0.000268,\n",
       " 0.000268,\n",
       " 0.000136,\n",
       " 0.000136,\n",
       " 0.000136,\n",
       " 0.000136,\n",
       " 0.000136,\n",
       " 3.999999999999989e-06,\n",
       " 3.999999999999989e-06,\n",
       " 3.999999999999989e-06,\n",
       " 3.999999999999989e-06,\n",
       " 3.999999999999989e-06,\n",
       " -0.00012800000000000002,\n",
       " -0.00012800000000000002,\n",
       " -0.00012800000000000002,\n",
       " -0.00012800000000000002,\n",
       " -0.00012800000000000002,\n",
       " -0.00026,\n",
       " -0.00026,\n",
       " -0.00026,\n",
       " -0.00026,\n",
       " -0.00026,\n",
       " -0.00039200000000000004,\n",
       " -0.00039200000000000004,\n",
       " -0.00039200000000000004,\n",
       " -0.00039200000000000004,\n",
       " -0.00039200000000000004,\n",
       " -0.0005240000000000002,\n",
       " -0.0005240000000000002,\n",
       " -0.0005240000000000002,\n",
       " -0.0005240000000000002,\n",
       " -0.0005240000000000002,\n",
       " -0.0006560000000000001,\n",
       " -0.0006560000000000001,\n",
       " -0.0006560000000000001,\n",
       " -0.0006560000000000001,\n",
       " -0.0006560000000000001,\n",
       " -0.0007880000000000001,\n",
       " -0.0007880000000000001,\n",
       " -0.0007880000000000001,\n",
       " -0.0007880000000000001,\n",
       " -0.0007880000000000001]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEARNING_RATE = .0004\n",
    "def scheduler(epoch, lr):\n",
    "    #scheduler = lambda epoch,lr: lr *.5 if epoch>5 else lr\n",
    "    if epoch < 5: return lr\n",
    "    else:          return LEARNING_RATE - LEARNING_RATE*.33*(epoch//5)\n",
    "\n",
    "[scheduler(i,LEARNING_RATE) for i in range(50)]# else LEARNING_RATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1d55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "8.65e-05\n",
      "8.65e-05\n",
      "8.65e-05\n",
      "8.65e-05\n",
      "8.65e-05\n",
      "7.5025e-05\n",
      "7.5025e-05\n",
      "7.5025e-05\n",
      "7.5025e-05\n",
      "7.5025e-05\n",
      "6.527125e-05\n",
      "6.527125e-05\n",
      "6.527125e-05\n",
      "6.527125e-05\n",
      "6.527125e-05\n",
      "5.6980562499999995e-05\n",
      "5.6980562499999995e-05\n",
      "5.6980562499999995e-05\n",
      "5.6980562499999995e-05\n",
      "5.6980562499999995e-05\n",
      "4.9933478125e-05\n",
      "4.9933478125e-05\n",
      "4.9933478125e-05\n",
      "4.9933478125e-05\n",
      "4.9933478125e-05\n",
      "4.3943456406249995e-05\n",
      "4.3943456406249995e-05\n",
      "4.3943456406249995e-05\n",
      "4.3943456406249995e-05\n",
      "4.3943456406249995e-05\n",
      "3.8851937945312494e-05\n",
      "3.8851937945312494e-05\n",
      "3.8851937945312494e-05\n",
      "3.8851937945312494e-05\n",
      "3.8851937945312494e-05\n",
      "3.4524147253515625e-05\n",
      "3.4524147253515625e-05\n",
      "3.4524147253515625e-05\n",
      "3.4524147253515625e-05\n",
      "3.4524147253515625e-05\n",
      "3.084552516548828e-05\n",
      "3.084552516548828e-05\n",
      "3.084552516548828e-05\n",
      "3.084552516548828e-05\n",
      "3.084552516548828e-05\n"
     ]
    }
   ],
   "source": [
    "LR_MAX = 0.0001\n",
    "LR_MIN = 0.00001\n",
    "LR_EXP_DECAY = 0.85\n",
    "\n",
    "def lrfn(epoch):\n",
    "    lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch//5) + LR_MIN\n",
    "    return lr\n",
    "for i  in range(50):\n",
    "    print(lrfn(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2bf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38d364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d996189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfdbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46bcd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Effects_of_Watching_Violence_Movies_On_The_Attudes_Concerning_Aggression_Among_Middle_Schoolboys_(13-17_years_old)_at_International_Schools_In_Kuala_Lumpur,_Malaysia'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \"Effects of Watching Violence Movies On The Attudes Concerning Aggression Among Middle Schoolboys (13-17 years old) at International Schools In Kuala Lumpur, Malaysia\"\n",
    "\"_\".join([i for i in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add73be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
