{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('./violence_recognizer')\n",
    "\n",
    "from violence_recognizer import trainer, model as modeling, predictor, data_generator\n",
    "from violence_recognizer.data_processing import Dataset, LabelingPattern\n",
    "import utility\n",
    "import config as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': '@resnet50.16.v0.video.npy', 'audio': '@yamnet.1.v0.audio.npy'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pattern = {'video': ('@'+cfg.BACKBONE+'.'+str(16)+'.'+str('v0')+'.video.npy').lower()}\n",
    "           #'audio': ('@'+'yamnet'+'.'+str(1)+'.'+str('v0')+'.audio.npy').lower()}\n",
    "file_pattern['audio'] = '@yamnet.1.v0.audio.npy'\n",
    "\n",
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 videos and 2000 audio files found in this dataset\n",
      "1208 videos and 1208 audio files found in this dataset\n",
      "After merging: 3208 files in this dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3208, 3208, 1062, 3208, 3208)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset= Dataset(video_features_path = cfg.MY_VIDEO_FEATURES_PATH,\n",
    "                   audio_features_path = cfg.MY_AUDIO_FEATURES_PATH,\n",
    "                   label_mapper = LabelingPattern.my_dataset,\n",
    "                   pattern = file_pattern)\n",
    "    \n",
    "rlvs = Dataset(video_features_path = cfg.RLVS_VIDEO_FEATURES_PATH,\n",
    "                audio_features_path =  cfg.RLVS_AUDIO_FEATURES_PATH,\n",
    "                label_mapper = LabelingPattern.rlvs,\n",
    "                pattern=file_pattern)\n",
    "\n",
    "rlvs.create_dataset()\n",
    "my_dataset.create_dataset()\n",
    "\n",
    "dataset = Dataset.merge_dataset([rlvs, my_dataset])\n",
    "(len(dataset.zipped_features_path),\n",
    " len(dataset.labels),\n",
    " len(dataset.silent_video_list),\n",
    " len(dataset.video_features_path),\n",
    " len(dataset.audio_features_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Backbone': 'Resnet50',\n",
      " 'Cross_Dataset': '',\n",
      " 'Debug': True,\n",
      " 'EPOCHS': 50,\n",
      " 'History_Path': './data/models_history/resnet50_my_dataset_rlvs_dataset_v0',\n",
      " 'If_Mxnet_Model': False,\n",
      " 'Input_Dim': (16, 2048),\n",
      " 'LEARNING_RATE': 0.003,\n",
      " 'Log_Path': './data/tensorboard_log/resnet50_my_dataset_rlvs_dataset_v0',\n",
      " 'MODEL NAME': 'resnet50_my_dataset_rlvs_dataset_v0',\n",
      " 'Model_Path': './data/saved_models/resnet50_my_dataset_rlvs_dataset_v0',\n",
      " 'Result_Path': './data/generated_result/resnet50_my_dataset_rlvs_dataset_v0',\n",
      " 'SEED': 0,\n",
      " 'Test_Partition': 0.1,\n",
      " 'Use_My_Dataset': True,\n",
      " 'Use_Rlvs_Dataset': True,\n",
      " 'Val_Partition': 0.1}\n"
     ]
    }
   ],
   "source": [
    "trainer.define_model_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.make_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " video (InputLayer)             [(None, 16, 2048)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 2048)        0           ['video[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 2048)        0           ['video[0][0]']                  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 2048)         0           ['tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 2048)        0           ['tf.math.reduce_mean[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 2048)        0           ['tf.math.multiply[0][0]',       \n",
      " da)                                                              'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " audio (InputLayer)             [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          262272      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           65600       ['audio[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64)          256         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64)           0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192)          0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            193         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 328,833\n",
      "Trainable params: 328,449\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = modeling.get_model(dimension = cfg.MODEL_DIMENSION,\n",
    "                           summary = True,\n",
    "                           input_shape = cfg.INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208 videos and 1208 audio files found in this dataset\n",
      "2000 videos and 2000 audio files found in this dataset\n",
      "After merging: 3208 files in this dataset\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = trainer.prepare_dataset(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 142s 2s/step - loss: 0.1721 - accuracy: 0.9414 - val_loss: 0.3648 - val_accuracy: 0.8889 - lr: 0.0030\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 6s 71ms/step - loss: 0.0783 - accuracy: 0.9753 - val_loss: 0.1592 - val_accuracy: 0.9340 - lr: 0.0030\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 4s 50ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.0776 - val_accuracy: 0.9653 - lr: 0.0030\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 0.0245 - val_accuracy: 0.9965 - lr: 0.0030\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0511 - accuracy: 0.9826 - val_loss: 0.0222 - val_accuracy: 0.9931 - lr: 0.0030\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.0303 - val_accuracy: 0.9931 - lr: 0.0027\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0220 - val_accuracy: 0.9965 - lr: 0.0026\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.0197 - val_accuracy: 0.9896 - lr: 0.0026\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 4s 45ms/step - loss: 0.0219 - accuracy: 0.9946 - val_loss: 0.0263 - val_accuracy: 0.9931 - lr: 0.0025\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.0703 - val_accuracy: 0.9618 - lr: 0.0025\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 4s 51ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 0.0024\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 4s 49ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0251 - val_accuracy: 0.9896 - lr: 0.0023\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.0317 - val_accuracy: 0.9861 - lr: 0.0023\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0191 - val_accuracy: 0.9965 - lr: 0.0022\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0095 - val_accuracy: 1.0000 - lr: 0.0022\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - 4s 49ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.0137 - val_accuracy: 0.9965 - lr: 0.0021\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - 4s 46ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0108 - val_accuracy: 0.9965 - lr: 0.0020\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - 4s 50ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.0108 - val_accuracy: 0.9965 - lr: 0.0020\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - 5s 57ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.0213 - val_accuracy: 0.9896 - lr: 0.0019\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0205 - val_accuracy: 0.9965 - lr: 0.0019\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - 5s 65ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0241 - val_accuracy: 0.9931 - lr: 0.0018\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0280 - val_accuracy: 0.9896 - lr: 0.0017\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.0260 - val_accuracy: 0.9896 - lr: 0.0017\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - 4s 48ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0198 - val_accuracy: 0.9861 - lr: 0.0016\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - 4s 47ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0183 - val_accuracy: 0.9896 - lr: 0.0016\n",
      "Saving file as pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "model, history = trainer.train_model(model,train_dataset,save_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r\"F:\\S-Home\\ViolenceRecognizer\\data\\saved_models\\resnet50_my_dataset_rlvs_dataset_v0\\model_015_0.009_1.000_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = data_generator.TensorflowDataGenerator(test_dataset, batch_size=cfg.BATCH_SIZE*2, val_partition=1)\n",
    "test_data, test_label = test_datagen.load_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "classification = predictor.evaluate_model(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model is ./data/saved_models/resnet50_my_dataset_rlvs_dataset_v0\\model_015_0.009_1.000_.h5\n",
      "{'BACKBONE': 'Resnet50',\n",
      " 'Best model': './data/saved_models/resnet50_my_dataset_rlvs_dataset_v0\\\\model_015_0.009_1.000_.h5',\n",
      " 'Class Mapping': {'No Physical Violence': 0, 'Physical Violence': 1},\n",
      " 'DISCARD SILENT VIDEO': False,\n",
      " 'INPUT_DIM': (16, 2048),\n",
      " 'My dataset': True,\n",
      " 'RLVS dataset': True,\n",
      " 'SEED': 0,\n",
      " 'Statistics': {'No of test samples': 320,\n",
      "                'classification_report': {'0': {'f1-score': 0.99,\n",
      "                                                'precision': 1.0,\n",
      "                                                'recall': 0.9801980198019802,\n",
      "                                                'support': 101},\n",
      "                                          '1': {'f1-score': 0.9954545454545455,\n",
      "                                                'precision': 0.9909502262443439,\n",
      "                                                'recall': 1.0,\n",
      "                                                'support': 219},\n",
      "                                          'accuracy': 0.99375,\n",
      "                                          'macro avg': {'f1-score': 0.9927272727272727,\n",
      "                                                        'precision': 0.995475113122172,\n",
      "                                                        'recall': 0.9900990099009901,\n",
      "                                                        'support': 320},\n",
      "                                          'weighted avg': {'f1-score': 0.9937329545454545,\n",
      "                                                           'precision': 0.9938065610859729,\n",
      "                                                           'recall': 0.99375,\n",
      "                                                           'support': 320}},\n",
      "                'confusion_matrix': {'FN': 0, 'FP': 2, 'TN': 99, 'TP': 219}},\n",
      " 'Time': '21-04-2022..20.56.11',\n",
      " 'model_name': 'resnet50_my_dataset_rlvs_dataset_v0'}\n",
      "Saving file as pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "predictor.verbose_result(classification, test_label)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b48c6828091cfb745be6a4b75bb089d3ad8bbbe95692486075e0ddeb2f435eb6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
