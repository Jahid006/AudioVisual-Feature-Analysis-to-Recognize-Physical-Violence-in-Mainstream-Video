{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, glob, time, shutil, string, os, joblib, datetime\n",
    "import sys, os, numpy as np\n",
    "from datetime import datetime\n",
    "import pickle, cv2, pims, tqdm\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:/S-Home/r2/data/features/my_dataset/video/i3d10s/\\\\notPhysicalViolence\\\\1026.Vanilla.npy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'i3d_resnet50_v1_kinetics400'\n",
    "feat_file = r\"F:/S-Home/r2/data/features/my_dataset/video\\notPhysicalViolence\\1026.Vanilla.npy\"\n",
    "feat_file = feat_file.replace('/video', f\"/video/{model_name.split('_')[0]+str(10)}s/\")\n",
    "feat_file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, decord\n",
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "decord.bridge.set_bridge('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "backbone = tf.keras.applications.ResNet50(include_top=False,weights=\"imagenet\",pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "backbone = tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\",pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeature(FileName,frames = 16, width=224, height=224):\n",
    "    \n",
    "    V = pims.Video(FileName) \n",
    "    duration = len(V) \n",
    "      \n",
    "    try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "    except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "    \n",
    "    Frames = np.array(V[frame_id_list])\n",
    "    Frames = np.array([cv2.resize(frame,(width,height)) for frame in Frames])\n",
    "    features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    return features\n",
    "\n",
    "\n",
    "def ExtractFeatureDecord(FileName,frames = 16, width=224, height=224):\n",
    "    \n",
    "    try:\n",
    "        V = VideoReader(FileName, width, height)\n",
    "        duration = len(V)\n",
    "        try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "        except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "        \n",
    "        Frames = V.get_batch(frame_id_list).asnumpy()\n",
    "        features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    \n",
    "    except:return ExtractFeature(FileName,frames,width,height)\n",
    "    return features\n",
    "\n",
    "def ExtractFeatureCV2(FileName,frames = 16, width=224, height=224):\n",
    "    \"\"\"get frames from video using cv2\"\"\"\n",
    "    V = cv2.VideoCapture(FileName)\n",
    "    duration = int(V.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    try:    frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=False))\n",
    "    except: frame_id_list = np.sort(np.random.choice(range(duration), frames, replace=True))\n",
    "    \n",
    "    Frames = np.array([V.read()[1] for i in frame_id_list])\n",
    "    Frames = np.array([cv2.resize(frame,(width,height)) for frame in Frames])\n",
    "    features = np.array(backbone.predict(preprocess_input(Frames)))\n",
    "    V.release()\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = glob.glob(r'H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\rlvs\\**\\*.avi',recursive=True)\n",
    "#data.extend(glob.glob(r'H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\my_dataset\\**\\*.avi',recursive=True))\n",
    "#data.extend(glob.glob(r'H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\rlvs\\**\\*.avi',recursive=True))\n",
    "data.extend(glob.glob(r'H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\rlvs\\**\\*.mp4',recursive=True))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [09:10<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#os.makedirs(r'video_features\\ResNet50\\notPhysicalViolence',exist_ok=True)\n",
    "failed =[]\n",
    "for i in tqdm.tqdm(data[:]): \n",
    "    try:\n",
    "        try:features = ExtractFeatureCV2(i)\n",
    "        except: features = ExtractFeatureDecord(i)\n",
    "        name = i.replace(i[-4:],'.npy')\n",
    "        \n",
    "        #sname = \"video_features\\ResNet50\\\\notPhysicalViolence\\{}.npy\".format(name)\n",
    "        #print(sname)\n",
    "        np.save(name,features,allow_pickle=True)\n",
    "    except:\n",
    "        failed.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 614/614 [18:52<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "data  = glob.glob(r'dataset\\PhysicalViolence\\*.mp4')\n",
    "print(len(data))\n",
    "os.makedirs(r'video_features\\ResNet50\\PhysicalViolence',exist_ok=True)\n",
    "\n",
    "for i in tqdm.tqdm(data): \n",
    "    try:features = ExtractFeatureDecord(i)\n",
    "    except: features = ExtractFeatureCV2(i)\n",
    "    name = i.split('\\\\')[-1][:-4]\n",
    "    sname = \"video_features\\ResNet50\\PhysicalViolence\\{}.npy\".format(name)\n",
    "    #print(sname)\n",
    "    np.save(sname,features,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [01:48<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%reset -f\n",
    "import gc\n",
    "import tensorflow_hub as hub,tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tqdm,numpy as np,os,tqdm,glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" read in a waveform file and convert to 16 kHz mono \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "start = 600\n",
    "#class_ = \"notPhysicalViolence\"\n",
    "audio_data = glob.glob(r'H:\\S-Home\\Home Office\\Violence\\archive\\v\\*.wav')\n",
    "os.makedirs(r\"H:\\S-Home\\Home Office\\Violence\\archive\\embedding\" , exist_ok=True)  \n",
    "\n",
    "'''import multiprocessing\n",
    "p = multiprocessing.Pool(3)\n",
    "embeddingss = p.map(save_embedding, audio_data[:6])'''\n",
    "\n",
    "\n",
    "def save_embedding(audio_path):\n",
    "    \"\"\" save the embedding of the audio file \"\"\"\n",
    "    gg, embeddings, kk = yamnet_model(load_wav_16k_mono(audio_path))  \n",
    "    name = audio_path.split('\\\\')[-1][:-4]+'.wav'\n",
    "    \n",
    "    sname = os.path.join(r'H:\\S-Home\\Home Office\\Violence\\archive\\embedding',name[:-4]+'.npy')\n",
    "    print(sname)\n",
    "    embeddings = np.max(embeddings,axis=0)*.25+np.mean(embeddings,axis=0)*.75 \n",
    "    embeddings = embeddings.reshape(-1)\n",
    "    print(embeddings.shape)\n",
    "\n",
    "    np.save(sname,embeddings , allow_pickle=True)\n",
    "    \n",
    "    \n",
    "for i in tqdm.tqdm(audio_data[start:]):\n",
    "    save_embedding(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = np.load('failed.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm,numpy as np,os,tqdm,glob\n",
    "import moviepy.editor as mpy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def video_to_wav(video):\n",
    "    \"\"\"convert video to wav using moviepy and save it in audio directory\"\"\"\n",
    "    if video.endswith('.wav'):return\n",
    "    clip = mpy.VideoFileClip(video)\n",
    "    audio = clip.audio\n",
    "    path = video[:-4] + \".wav\"\n",
    "    audio.write_audiofile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifFileExist(file):\n",
    "    \"\"\"check if file exists\"\"\"\n",
    "    if os.path.exists(file):return True\n",
    "    else:return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = glob.glob(r\"H:\\S-Home\\Home Office\\Violence\\archive\\Real Life Violence Dataset\\*\\*.avi\", recursive=True)\n",
    "data.extend(glob.glob(r\"H:\\S-Home\\Home Office\\Violence\\archive\\Real Life Violence Dataset\\*\\*.mp4\", recursive=True))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:51<00:00, 38.89it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(data): \n",
    "    name = i.split('\\\\')[-1][:-4]\n",
    "    sname = \"H:\\S-Home\\Home Office\\Violence\\\\archive\\\\v2\\{}.npy\".format(name)\n",
    "    if ifFileExist(sname):continue\n",
    "    try:features = ExtractFeatureDecord(i)\n",
    "    except: features = ExtractFeatureCV2(i)\n",
    "\n",
    "    #print(sname)\n",
    "    np.save(sname,features,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dimension = 512,summary = False,input_shape = INPUT_DIM):\n",
    "    \n",
    "    FeatureInput = Input(shape=input_shape)\n",
    "    Average_feature = layers.Flatten()(FeatureInput) if  IF_MXNET_MODEL else tf.reduce_max(FeatureInput,-2)*.25 + tf.reduce_mean(FeatureInput,-2)*.75\n",
    "    \n",
    "    AudioInput =   Input(shape=(1024))\n",
    "    audio_ = layers.Dense(dimension//4,kernel_initializer='normal', activation='linear')(AudioInput)\n",
    "    audio_ = layers.BatchNormalization()(audio_)\n",
    "    audio_ = layers.Activation(tf.nn.relu)(audio_)\n",
    "    audio_ = layers.Dropout(.5)(audio_)\n",
    "    \n",
    "    video_ = layers.Flatten()(Average_feature)\n",
    "    video_ = layers.Dense(dimension//2,kernel_initializer='normal', activation='linear')(video_)\n",
    "    video_ = layers.BatchNormalization()(video_)\n",
    "    video_ = layers.Activation(tf.nn.relu)(video_)\n",
    "    video_ = layers.Dropout(.5)(video_)\n",
    "    \n",
    "    combined = layers.concatenate([video_,audio_],axis=1)\n",
    "    \n",
    "    output = layers.Dense(1,kernel_initializer='normal', activation='sigmoid',name = 'classifier')(combined)\n",
    "    \n",
    "    model = Model(inputs= [FeatureInput,AudioInput], outputs = output)\n",
    "    model.compile(optimizer=tf.optimizers.Nadam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    if summary:print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUnable to start Kernel 'tf26 (Python 3.8.0)' due to connection timeout. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(glob.glob('abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# This function translate speech to text\n",
    "def speech_to_text(file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = sr.AudioFile(file)\n",
    "    with audio as source:\n",
    "        speech = recognizer.record(source)\n",
    "        try:\n",
    "            # Call recognizer with audio and language\n",
    "            text = recognizer.recognize_google(speech, language='pt-BR')\n",
    "            print(\"Você disse: \" + text)\n",
    "            return text\n",
    "        # If recognizer don't understand\n",
    "        except:\n",
    "            print(\"Não entendi\")\n",
    "\n",
    "def mp4_to_wav(file):\n",
    "    audio = AudioSegment.from_file(file, format=\"mp4\")\n",
    "    audio.export(\"audio.wav\", format=\"wav\")\n",
    "    return audio\n",
    "\n",
    "def mp4_to_wav_mem(file):\n",
    "    audio = AudioSegment.from_file_using_temporary_files(file, 'mp4')\n",
    "    file = io.BytesIO()\n",
    "    file = audio.export(file, format=\"wav\")\n",
    "    file.seek(0)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0m\u001b[0;32m   1184\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening 'H:\\\\S-Home\\\\RecognizingPhysicalViolence\\\\dataset\\\\my_dataset\\\\video\\\\PhysicalViolence\\\\3017.mp4': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9260/2190200349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\my_dataset\\video\\PhysicalViolence\\3017.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audio_path = r\"H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\my_dataset\\video\\PhysicalViolence\\3017.mp4\"\n",
    "y, sr = librosa.load(audio_path)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9260/3778139762.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0maudio_only\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp4_to_wav_mem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9260/2489364789.py\u001b[0m in \u001b[0;36mmp4_to_wav_mem\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmp4_to_wav_mem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file_using_temporary_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file_using_temporary_files\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdevnull\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconversion_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m         \u001b[0mp_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\Anaconda\\envs\\tf26\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "audio_path = r\"H:\\S-Home\\RecognizingPhysicalViolence\\test_data\\2009.mp4\"\n",
    "\n",
    "file = open(audio_path, 'rb').read()\n",
    "\n",
    "file = io.BytesIO(file)\n",
    "audio_only = mp4_to_wav_mem(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# files                                                                         \n",
    "src = \"transcript.mp3\"\n",
    "dst = \"test.wav\"\n",
    "\n",
    "# convert wav to mp3                                                            \n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio(video_path,audio_path):\n",
    "    \"\"\"convert video to audio using ffmpeg\"\"\"\n",
    "    import subprocess\n",
    "    subprocess.call(['ffmpeg', '-i', video_path, '-f', 'wav', audio_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "audio_path = r\"H:\\S-Home\\RecognizingPhysicalViolence\\dataset\\my_dataset\\audio\\PhysicalViolence\\3017.wav\"\n",
    "y, sr = librosa.load(audio_path)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 488)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module decord.video_loader in decord:\n",
      "\n",
      "NAME\n",
      "    decord.video_loader - Video Loader.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        VideoLoader\n",
      "    \n",
      "    class VideoLoader(builtins.object)\n",
      "     |  VideoLoader(uris, ctx, shape, interval, skip, shuffle, prefetch=0)\n",
      "     |  \n",
      "     |  Multiple video loader with advanced shuffling and batching methods.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  uris : list of str\n",
      "     |      List of video paths.\n",
      "     |  ctx : decord.Context or list of Context\n",
      "     |      The context to decode the video file, can be decord.cpu() or decord.gpu().\n",
      "     |      If ctx is a list, videos will be evenly split over many ctxs.\n",
      "     |  shape : tuple\n",
      "     |      Returned shape of the batch images, e.g., (2, 320, 240, 3) as (Batch, H, W, 3)\n",
      "     |  interval : int\n",
      "     |      Intra-batch frame interval.\n",
      "     |  skip : int\n",
      "     |      Inter-batch frame interval.\n",
      "     |  shuffle : int\n",
      "     |      Shuffling strategy. Can be\n",
      "     |      `0`:  all sequential, no seeking, following initial filename order\n",
      "     |      `1`:  random filename order, no random access for each video, very efficient\n",
      "     |      `2`:  random order\n",
      "     |      `3`:  random frame access in each video only.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __init__(self, uris, ctx, shape, interval, skip, shuffle, prefetch=0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Get number of batches in each epoch.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      int\n",
      "     |          number of batches in each epoch.\n",
      "     |  \n",
      "     |  __next__(self)\n",
      "     |      Get the next batch.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ndarray, ndarray\n",
      "     |          Frame data and corresponding indices in videos.\n",
      "     |          Indices are [(n0, k0), (n1, k1)...] where n0 is the index of video, k0 is the index\n",
      "     |          of frame in video n0.\n",
      "     |  \n",
      "     |  next(self)\n",
      "     |      Alias of __next__ for python2.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Reset loader for next epoch.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "\n",
      "FILE\n",
      "    d:\\program\\anaconda\\envs\\pytorch\\lib\\site-packages\\decord\\video_loader.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import decord\n",
    "\n",
    "help(decord.video_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e171f4d364008335a6a8c2f0c83752293e6a6be7e5b4134bb1362bfd4a9df0db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('tf26': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
