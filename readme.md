Analyze Audio-Visual Features to Recognize Physical Violence in the Mainstream Videos

The project utilises both audio and video features to recognize violent content in the mainstream videos. To reduce the training time, we decided to extract video and audio features beforehand and then use these features to train our violence recognizer model.

For feature extraction, please follow readme.md file in feature_extractor folder.

You can do both training and inference form main.py file.

Be careful when you configure config.py file which contains all configurations of this project. Follow the comment to change to it to your likings.

For more in-depth instructions, follow how_to_use.ipynb!!!
